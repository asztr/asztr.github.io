<!DOCTYPE html>
<head>
	<title>Alejandro Sztrajman</title>

	<meta http-equiv="Content-Type" content="text/html;charset=utf-8">
	<link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
	<style type="text/css" media="all">@import url("css/ploneCustom.css");</style>
	<!-- <style type="text/css" media="all">@import url("css/ploneIEFixes.css");</style> -->
	<style type="text/css" media="all">@import url("css/items.css");</style>
	<link rel="stylesheet" href="./css/aicons/css/academicons.min.css"/>
	<link href="./css/fawesome/css/all.css" rel="stylesheet">
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VV22DCGBKT"></script>
	<script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-VV22DCGBKT');</script>
</head>

<body>
	<div class="navbar">
		<div class="navlinks">
			<li><a href="#publications">Publications</a></li>
			<li><a href="#patents">Patents</a></li>
			<li><a href="#codes">Codes</a></li>
			<!-- <li><a href="#talks">Talks</a></li> -->
			<li><a href="#teaching">Teaching</a></li>
			<!--<li><a href="#bground">Background</a></li>-->
		</div>
	</div>
	<div class="documentContent">
		<!-- ################################################################ -->
		<table>
			<tr>
				<td width="280px" valign="top">
					<br><br>
					<!--<img src="./img/portrait8b-circle-800-compressed-fs8.png" width="100%">-->
					<img src="./img/portrait9-lr.png" width="100%">
				</td>
				<td width="50px"></td>
				<td align="justify" valign="top">
					<h2>Alejandro Sztrajman</h2>
					<table>
						I'm a postdoctoral research associate
						in the <a href="https://www.cl.cam.ac.uk/research/rainbow/">Rainbow Group</a>
						at the
						<a href="https://www.cam.ac.uk/">University of Cambridge</a>, where I work with Profs.
						<a href="https://www.cl.cam.ac.uk/~aco41/">Cengiz Öztireli</a> and
						<a href="https://www.cl.cam.ac.uk/~rkm38/">Rafał Mantiuk</a>.
						I hold a PhD in Computer Science
						<!--in the <a href="http://www.cs.ucl.ac.uk/research/vr/">Virtual Environments and Computer Graphics Group</a>-->
						from <a href="http://www.ucl.ac.uk/">University College London</a> (UCL), where I worked at the
						<a href="http://reality.cs.ucl.ac.uk/home.html">Digital Reality Lab</a>,
						under the supervision of Profs.
						<a href="http://reality.cs.ucl.ac.uk/weyrich.php">Tim Weyrich</a> and
						<a href="http://www.homepages.ucl.ac.uk/~ucactri/">Tobias Ritschel</a>.
						My research is in the intersection between machine learning and visual computing,
						combining methods from neural fields, hypernetworks, physically-based rendering
						and generative models.
						<!--representation of photorealistic material appearance and scene illumination.-->
						<!-- appearance acquisition, visual perception, material synthesis, efficient rendering -->
						My PhD project was funded by a
						<a href="https://marie-sklodowska-curie-actions.ec.europa.eu/">Marie Curie Fellowship</a>,
						granted by the European Commission.
						<!--in the context of the
						<a href="http://www.distro-itn.eu/">DISTRO ITN</a>.-->
						During my PhD I also worked as research intern at
						<a href="https://www.microsoft.com/applied-sciences">Microsoft</a> and
						<a href="https://www.substance3d.com/">Adobe</a>.
						<!--<a href="https://ec.europa.eu/research/mariecurieactions/">Marie Skłowdowska-Curie programme</a>.-->
						Before joining UCL, I obtained a BSc in Physics from the
						<a href="https://uba.ar/">University of Buenos Aires</a>,
						and I was a visiting student at the
						<a href="https://www.cs.columbia.edu/cg/">Columbia Computer Graphics Group</a>.
						<!--under the supervision of Profs.
						<a href="https://www.dgp.toronto.edu/~eitan/">Eitan Grinspun</a>
						and
						<a href="https://cs.uwaterloo.ca/~c2batty/">Christopher Batty</a>.-->
						<!--where I worked on physics-based numerical simulations.-->
						<br>
						<br>
						<br>
						<div align="right" style="font-size:14px; font-weight:Italic;">
							<b>Contact</b> <img src="./img/cam2.png" height="12px"/><br>
							Room SE18<br>
							Computer Laboratory<br>
							William Gates Building<br>
							15 JJ Thomson Avenue<br>
							University of Cambridge, UK<br>
							<!--Cambridge, CB3 0FD<br>United Kingdom<br>-->
							<br>
							<a id="hoverAlpha" href="mailto:alejandro.sztrajman@cl.cam.ac.uk"><img class="hoverZoom" width="35px" src="./img/mail.png"></a>
							<a id="hoverAlpha" href="http://ar.linkedin.com/in/asztrajman"><img class="hoverZoom" width="35px" src="./img/linkedin.png"></a>
							<a id="hoverAlpha" href="https://github.com/asztr"><i class="fab fa-github" style="font-size:35px; vertical-align:middle; color:#000000;"></i></a>
							<!--<a id="hoverAlpha" href=""><i class="ai ai-cv" style="padding:8px; border-radius:50%; font-size:18px; vertical-align:middle; background-color:#000000; color:#ffffff;"></i></a>-->
							<a id="hoverAlpha" href="https://scholar.google.com/citations?user=XFRNQf8AAAAJ&hl=en"><i class="ai ai-google-scholar" style="vertical-align:middle; font-size:24px; height:18px; padding:8px; border-radius:50%; background-color:#2c930ac7; color:#ffffff;"></i></a>
							<!--<a id="hoverAlpha" href="https://scholar.google.com/citations?user=XFRNQf8AAAAJ&hl=en"><i class="fa-brands fa-google-scholar" style="font-size:35px; vertical-align:middle;"></i></a>-->
							<!--<a id="hoverAlpha" href="https://scholar.google.com/citations?user=XFRNQf8AAAAJ&hl=en"><img class="hoverZoom" width="35px" src="./img/scholar.png"></a>-->
						</div>
					</table>
				</td>
			</tr>
		</table>
		<!-- ################################################################ -->
		<h2 id="publications">Publications</h2>
		<table class="publications">
			<tr>
				<td>
					<!--<a href="">-->
						<img id="nobox" src="./publications/hyperdiff2024/hyperdiff_thumb3.jpg" style="width:100%;">
					<!--</a>-->
				</td>
				<td>
					<b>NeuMaDiff: Neural Material Synthesis via Hyperdiffusion</b><br>
					Chenliang Zhou, Zheyuan Hu, <b>Alejandro Sztrajman</b>, Yancheng Cai, Yaru Liu, Cengiz Oztireli.<br>
					<span id="venue">In Review, 2024.</span><br>
					<div id="keywords">Keywords: <keys>Vision-Language Models (VLMs), Generative AI, Neural Fields, Material Appearance.</keys></div><br>
					<div id="links">
						<a href="https://arxiv.org/abs/2411.12015">arXiv</a>
						<a href="https://arxiv.org/pdf/2411.12015">PDF</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://arxiv.org/abs/2411.02347">
						<img id="nobox" src="./publications/pb_nbrdf2024/pbnbrdf_thumbnail2.jpg" style="width:80%;">
					</a>
				</td>
				<td>
					<b>Physically Based Neural Bidirectional Reflectance Distribution Function</b><br>
					Chenliang Zhou, <b>Alejandro Sztrajman</b>, Gilles Rainer, Fangcheng Zhong, Fazilet Gokbudak, Zhilin Guo, Weihao Xia, Rafal Mantiuk, Cengiz Oztireli.<br>
					<span id="venue">In Review, 2024.</span><br>
					<div id="keywords">Keywords: <keys>Physics-Informed Neural Networks, Neural Fields, Physics-based Rendering.</keys></div><br>
					<div id="links">
						<a href="https://arxiv.org/abs/2411.02347">arXiv</a>
						<a href="https://arxiv.org/pdf/2411.02347">PDF</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://openreview.net/pdf?id=yzfi15eVI7">
						<img id="nobox" src="./publications/ihypertime2022/ihypertime-thumbnail.jpg">
					</a>
				</td>
				<td>
					<b>iHyperTime: Interpretable Time Series Generation with Implicit Neural Representations</b><br>
					Elizabeth Fons, <b>Alejandro Sztrajman</b>, Yousef El-Laham, Andrea Coletta, Alexandros Iosifidis, Svitlana Vyetrenko.<br>
					<span id="venue">Transactions on Machine Learning Research (TMLR), 2024.</span><br>
					<div id="keywords">Keywords: <keys>Time-series, Neural Fields, Generative Models, Interpretability, Hypernetworks.</keys></div><br>
					<div id="links">
						<a href="https://openreview.net/forum?id=GSnGPgeoS5">OpenReview</a>
						<a href="https://openreview.net/pdf?id=GSnGPgeoS5">PDF</a>
						<!--<a href="https://openreview.net/pdf?id=yzfi15eVI7">PDF</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://chenliang-zhou.github.io/FrePolad">
						<img id="nobox" src="./publications/frepolad2024/frepolad_thumbnail2.jpg">
					</a>
				</td>
				<td>
					<b>FrePolad: Frequency-Rectified Point Latent Diffusion for Point Cloud Generation</b><br>
					Chenliang Zhou, Fangcheng Zhong, Param Hanji, Zhilin Guo, Kyle Thomas Fogarty, <b>Alejandro Sztrajman</b>, Hongyun Gao, Cengiz Oztireli.<br>
					<span id="venue">European Conference on Computer Vision (ECCV), 2024.</span><br>
					<div id="keywords">Keywords: <keys>Diffusion Models, 3D Point Clouds.</keys></div><br>
					<div id="links">
						<a href="https://chenliang-zhou.github.io/FrePolad">Project</a>
						<a href="https://arxiv.org/abs/2311.12090">arXiv</a>
						<a href="https://arxiv.org/pdf/2311.12090.pdf">PDF</a>
						<a href="https://github.com/Chenliang-Zhou/FrePolad">Code</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://arxiv.org/abs/2311.15783">
						<img src="./publications/nbrdf+2023/nbrdf+_thumbnail3.jpg">
					</a>
				</td>
				<td>
					<b>Hypernetworks for Generalizable BRDF Estimation</b><br>
					Fazilet Gozbudak, <b>Alejandro Sztrajman</b>, Chenliang Zhou, Fangcheng Zhong, Rafal Mantiuk, Cengiz Oztireli.<br>
					<span id="venue">European Conference on Computer Vision (ECCV), 2024.</span><br>
					<div id="keywords">Keywords: <keys>Neural Fields, Hypernetworks, Generalizable Models, Material Appearance.</keys></div><br>
					<div id="links">
						<a href="https://faziletgokbudak.github.io/HyperBRDF/">Project</a>
						<a href="https://arxiv.org/abs/2311.15783">arXiv</a>
						<a href="https://arxiv.org/pdf/2311.15783.pdf">PDF</a>
						<a href="https://github.com/faziletgokbudak/Hyper-neural-materials">Code</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://arxiv.org/abs/2306.08943">
						<img id="nobox" src="./publications/cnf2023/cnf2023-thumbnail.jpg">
					</a>
				</td>
				<td>
					<b>Neural Fields with Hard Constraints of Arbitrary Differential Order</b><br>
					Fangcheng Zhong, Kyle Fogarty, Param Hanji, Tianhao Wu, <b>Alejandro Sztrajman</b>, Andrew Spielberg, Andrea Tagliasacchi, Petra Bosilj, Cengiz Oztireli.<br>
					<span id="venue">Conference on Neural Information Processing Systems (NeurIPS), 2023.</span><br>
					<div id="keywords">Keywords: <keys>Neural Fields, Hypernetworks, Constrained Learning.</keys></div><br>
					<div id="links">
						<a href="https://zfc946.github.io/CNF.github.io/">Project</a>
						<a href="https://arxiv.org/abs/2306.08943">arXiv</a>
						<a href="https://arxiv.org/pdf/2306.08943.pdf">PDF</a>
						<a href="https://github.com/zfc946/CNF">Code</a>
						<a href="./publications/cnf2023/cnf2023-poster.png">Poster</a>
						<a href="https://neurips.cc/virtual/2023/poster/70460">Presentation</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://www.cl.cam.ac.uk/~rkm38/pdfs/ashraf2023_oled_calibration.pdf">
						<img id="nobox" src="./publications/2023_hvei/hvei_thumbnail_crop.jpg" style="width:90%;">
					</a>
				</td>
				<td>
					<b>Color Calibration Methods for OLED Displays</b><br>
					Maliha Ashraf, <b>Alejandro Sztrajman</b>, Dounia Hammou, Rafał Mantiuk.<br>
					<span id="venue">Electronic Imaging, 2023.</span><br>
					<div id="keywords">Keywords: <keys>Color Correction, Implicit Neural Representations.</keys></div><br>
					<div id="links">
						<a href="https://library.imaging.org/ei/articles/36/16/COLOR-166">Page</a>
						<a href="https://www.cl.cam.ac.uk/~rkm38/pdfs/ashraf2023_oled_calibration.pdf">PDF</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://openreview.net/forum?id=DZ2FaoMhWRb">
						<img id="nobox" src="./publications/hypertime2022/hypertime-thumbnail2.jpg">
					</a>
				</td>
				<td>
					<b>HyperTime: Implicit Neural Representations for Time-Series</b><br>
					Elizabeth Fons, <b>Alejandro Sztrajman</b>, Yousef El-Laham, Alexandros Iosifidis, Svitlana Vyetrenko.<br>
					<span id="venue">NeurIPS SyntheticData4ML, 2022.</span><br>
					<div id="keywords">Keywords: <keys>Time-series, Neural Fields, Signal Processing, Hypernetworks.</keys></div><br>
					<div id="links">
						<a href="https://openreview.net/forum?id=DZ2FaoMhWRb">OpenReview</a>
						<a href="https://openreview.net/pdf?id=DZ2FaoMhWRb">PDF</a>
						<a href="https://openreview.net/attachment?id=DZ2FaoMhWRb&name=supplementary_material">Supplemental</a>
						<!--<a href="https://arxiv.org/abs/2208.05836">arXiv</a>
						<a href="https://arxiv.org/pdf/2208.05836">PDF</a>
						<a href="./publications/hypertime2022/fons2022hypertime.bib">BibTeX</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="./publications/nbrdf2021/nbrdf.html">
						<img src="./publications/nbrdf2021/thumbnail.jpg">
					</a>
				</td>
				<td>
					<b>Neural BRDF Representation and Importance Sampling</b>
					(<font style="font-variant: small-caps; color:red;">Wiley Top Cited Paper</font>)<br>
					<b>Alejandro Sztrajman</b>, Gilles Rainer, Tobias Ritschel, Tim Weyrich.<br>
					<span id="venue">Computer Graphics Forum (CGF), 2021 (Oral Presentation at EGSR 2022).</span><br>
					<div id="keywords">Keywords: <keys>Material Appearance, Neural Fields, Meta-learning, Hypernetworks, Differentiable Rendering, Monte Carlo Importance Sampling.</keys></div><br>
					<div id="links">
						<a href="./publications/nbrdf2021/nbrdf.html">Project</a>
						<!--<a href="http://arxiv.org/abs/2102.05963">arXiv</a>-->
						<a href="./publications/nbrdf2021/sztrajman2021nbrdf.pdf">PDF</a>
						<a href="./publications/nbrdf2021/sztrajman2021nbrdf-lowres.pdf">PDF (lowres)</a>
						<a href="https://github.com/asztr/Neural-BRDF">Code</a>
						<a href="./publications/nbrdf2021/sztrajman2021neural-slides.pdf">Slides</a>
						<a href="./publications/nbrdf2021/nbrdf.html#nbrdf_webgl">WebGL Demo</a>
						<a href="./publications/nbrdf2021/supplemental/pdfs/supplemental_merl.pdf">Supplemental</a>
						<!--<a href="./publications/nbrdf2021/sztrajman2021nbrdf.bib">BibTeX</a>-->
						<!--<a href="http://doi.org/10.1111/cgf.14335">DOI</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="./publications/ijcnn2022/ijcnn2022.html">
						<img src="./publications/ijcnn2022/ijcnn2022-thumbnail2.jpg">
					</a>
				</td>
				<td>
					<b>Fast Blue Noise Generation via Unsupervised Learning</b><br>
					*Daniele Giunchi, *<b>Alejandro Sztrajman</b>, Anthony Steed.<br>
					<span id="venue">International Joint Conference on Neural Networks (IJCNN), 2022 (Oral Presentation).</span><br>
					<div id="keywords">Keywords: <keys>Blue-Noise, Unsupervised Learning, Dithering, Monte Carlo Integration.</keys></div><br>
					<div id="links">
						<a href="./publications/ijcnn2022/ijcnn2022.html">Project</a>
						<a href="./publications/ijcnn2022/ijcnn2022-preprint.pdf">PDF</a>
						<a href="https://github.com/asztr/BlueNoise">Code</a>
						<a href="./publications/ijcnn2022/ijcnn2022-poster.pdf">Poster</a>
						<a href="./publications/ijcnn2022/ijcnn2022-slides.pdf">Slides</a>
						<!--<a href="./publications/ijcnn2022/giunchi2022bluenoise.bib">BibTeX</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://discovery.ucl.ac.uk/id/eprint/10152596">
						<!--<img id="nobox" src="./publications/phdthesis/phdthesis-thumbnail4-small.jpg">-->
						<img id="nobox" src="./img/ucl-banner-black4-short.png">
					</a>
				</td>
				<td>
					<b>Machine Learning Applications in Appearance Modelling</b><br>
					<b>Alejandro Sztrajman.</b><br>
					<span id="venue">University College London, 2022 (PhD Thesis).</span><br>
					<div id="keywords">
						Reviewers: Profs.
						<a href="https://scholar.google.co.uk/citations?hl=en&user=IRMX4-4AAAAJ">Lourdes Agapito</a> and
						<a href="http://giga.cps.unizar.es/~diegog/">Diego Gutierrez</a>.
					</div>
					<br>
					<div id="links">
						<a href="https://discovery.ucl.ac.uk/id/eprint/10152596">UCL Repository</a>
						<a href="https://discovery.ucl.ac.uk/id/eprint/10152596/7/asztrajman_PhD_thesis.pdf">PDF</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="./publications/sketch2021/sketch2021.html">
						<!--<img src="./publications/sketch2021/sketch-thumbnail.jpg">-->
						<img src="./publications/sketch2021/imgs/teaser1-lr2.jpg">
					</a>
				</td>
				<td>
					<b>Mixing Modalities of 3D Sketching and Speech for Interactive Model Retrieval in Virtual Reality</b><br>
					Daniele Giunchi, <b>Alejandro Sztrajman</b>, Stuart James, Anthony Steed.<br>
					<span id="venue">ACM International Conference on Interactive Media Experiences (IMX), New York, USA, Jun 2021 (Oral Presentation).</span><br>
					<div id="keywords">Keywords: <keys>Virtual Reality, 3D Sketching, CNNs, Human-in-the-loop.</keys></div><br>
					<div id="links">
						<a href="./publications/sketch2021/sketch2021.html">Project</a>
						<!--<a href="http://arxiv.org/abs/1808.06715">[arXiv]</a>-->
						<a href="./publications/sketch2021/giunchi-etal_imx21.pdf">PDF</a>
						<a href="./publications/sketch2021/giunchi-etal_imx21_lowres.pdf">PDF (lowres)</a>
						<a href="./publications/sketch2021/imx21c-sub1037-i11.pdf">Supplemental</a>
						<!--<a href="./publications/sketch2021/giunchi2021sketch3d.bib">BibTeX</a>-->
						<!--<a href="http://dl.acm.org/doi/10.1145/3452918.3458806">[DOI]</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="./publications/3dv2020/3dv2020.html">
						<img id="nobox" src="./publications/3dv2020/img/3dv-thumbnail.jpg">
					</a>
				</td>
				<td>
					<b>High-Dynamic-Range Lighting Estimation from Face Portraits</b><br>
					<b>Alejandro Sztrajman</b>, Alexandros Neophytou, Tim Weyrich, Eric Sommerlade.<br>
					<span id="venue">International Conference on 3D Vision (3DV), Fukoka, Japan, Nov 2020 (Oral Presentation).</span><br>
					<div id="keywords">Keywords: <keys>HDR Lighting, CNNs, Inverse Rendering, Light Estimation.</keys></div><br>
					<div id="links">
						<a href="./publications/3dv2020/3dv2020.html">Project</a>
						<a href="./publications/3dv2020/3dv-paper.pdf">PDF</a>
						<a href="./publications/3dv2020/3dv-long+notes.pdf">Slides</a>
						<a href="./publications/3dv2020/3dv2020.html#short">Short Presentation</a>
						<a href="./publications/3dv2020/3dv2020.html#long">Long Presentation</a>
						<a href="./publications/3dv2020/3dv2020.html#poster">Poster</a>
						<a href="./publications/3dv2020/additional_material.zip">Supplemental</a>
						<!--<a href="./publications/3dv2020/3dv2020.bib">BibTeX</a>-->
						<!--<a href="http://reality.cs.ucl.ac.uk/projects/envmaps/sztrajman2020hdr.html">Webpage</a>
						<a href="http://reality.cs.ucl.ac.uk/projects/envmaps/sztrajman2020hdr.pdf">PDF</a>
						<a href="http://reality.cs.ucl.ac.uk/projects/envmaps/sztrajman2020hdr.bib">BibTeX</a>-->
						<!--<a href="http://dx.doi.org/10.1109/3DV50981.2020.00045">DOI</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman2019image-based.html">
						<img id="nobox" src="./publications/jcgt2019/jcgt2019_thumbnail_20pct.jpeg">
					</a>
				</td>
				<td>
					<b>Image-based remapping of spatially-varying material appearance</b><br>
					<b>Alejandro Sztrajman</b>, Jaroslav Krivanek, Alexander Wilkie, Tim Weyrich.<br>
					<span id="venue">Journal of Computer Graphics Techniques (JCGT), 8(4), pp. 1-30, 2019.</span><br>
					<div id="keywords">Keywords: <keys>Material Appearance, SVBRDF, Non-linear Optimization, Neural Networks.</keys></div><br>
					<div id="links">
						<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman2019image-based.html">Project</a>
						<a href="http://jcgt.org/published/0008/04/01/paper.pdf">PDF</a>
						<a href="http://jcgt.org/published/0008/04/01/paper-lowres.pdf">PDF (lowres)</a>
						<!--<a href="http://jcgt.org/published/0008/04/01/bibtex.bib">BibTeX</a>-->
						<a href="https://github.com/asztr/SVBRDF-Remapping">Code</a>
						<a href="http://jcgt.org/published/0008/04/01/supplemental.zip">Supplemental</a>
						<!--<a href="http://arxiv.org/abs/1808.06715">[arXiv]</a>-->
						<!--<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman2019image-based.pdf">PDF</a>
						<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman2019image-based-lowres.pdf">PDF (lowres)</a>
						<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman2019image-based.bib">BibTeX</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman17image-based.html">
						<img id="nobox" src="./publications/mam2017/mam2017_thumbnail.jpg">
					</a>
				</td>
				<td>
					<b>Image-based remapping of material appearance</b><br>
					<b>Alejandro Sztrajman</b>, Jaroslav Krivanek, Alexander Wilkie, Tim Weyrich.<br>
					<span id="venue">Eurographics Workshop on Material Appearance Modeling (MAM), Helsinki, Finland, Jun 2017 (Oral Presentation).</span><br>
					<div id="keywords">Keywords: <keys>Material Appearance, BRDF, Non-linear Optimization.</keys></div><br>
					<div id="links">
						<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman17image-based.html">Project</a>
						<a href="https://discovery.ucl.ac.uk/id/eprint/10038784/1/sztrajman17image-based_egdiglib.pdf">PDF</a>
						<!--<a href="./publications/mam2017/mam2017.bib">BibTeX</a>-->
						<!--<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman17image-based.pdf">PDF</a>-->
						<!--<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman17image-based.bib">BibTeX</a>-->
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="https://doi.org/10.1119/1.4976660">
						<img id="nobox" src="./publications/2017_tpt/tpt_thumbnail5.jpg">
					</a>
				</td>
				<td>
					<b>An Easy Way to One-Dimensional Elastic Collisions</b><br>
					Jorge Sztrajman, <b>Alejandro Sztrajman</b>.<br>
					<span id="venue">The Physics Teacher (TPT) 55 (3), pp. 164-165.</span><br>
					<div id="keywords">Keywords: <keys>Physics, Education.</keys></div><br>
					<div id="links">
						<a href="https://doi.org/10.1119/1.4976660">DOI</a>
						<a href="https://discovery.ucl.ac.uk/id/eprint/10043321/1/Physics%20Teacher%20-%20An%20Easy%20Way%20to%20One-Dimensional%20Elastic%20Collisions.pdf">PDF</a>
					</div>
				</td>
			</tr>

			<tr>
				<td>
					<a href="http://www.eudeba.com.ar/Papel/9789502324432/Electromagnetismo+elemental">
						<img src="./publications/roederer/roederer_tapa_lowres.jpeg" style="width:65%;">
					</a>
				</td>
				<td>
					<b>Elementary Electromagnetism</b><br>
					Juan G. Roederer.<br>
					<span id="venue">Buenos Aires University Press, Buenos Aires (2015).</span><br>
					<br>
					<div> <!-- style="font-size:13px; line-height:110%">-->
						I coordinated the editorial team
						<!--<a href="./publications/roederer/photo-team-book2.jpg">editorial team</a>-->
						behind the undergraduate textbook by
						<a href="http://en.wikipedia.org/wiki/Juan_Gualterio_Roederer">Prof. Juan Roederer</a>.
						<!--The book includes a final chapter on <i>Electronics</i> by
						<a href="http://es.wikipedia.org/wiki/Jorge_Aliaga">Prof. Jorge Aliaga</a>.-->
						The book was first published in
						<a href="http://www.eudeba.com.ar/Papel/9789502324432/Electromagnetismo+elemental">2015</a>.
						A second edition was released in
						<a href="https://www.eudeba.com.ar/Papel/9789502328546/Electromagnetismo+elemental">2018</a>,
						and a digital edition followed in
						<a href="https://www.eudeba.com.ar/E-book/9789502330167/Electromagnetismo+elemental">2020</a>.
						<br>
						<div id="links">
							<a href="http://www.eudeba.com.ar/Papel/9789502324432/Electromagnetismo+elemental">Book</a>
							<a href="./publications/roederer/prefacio.pdf">Preface</a>
							<a href="http://nexciencia.exactas.uba.ar/el-autor-en-persona">Media Coverage</a>
						</div>
						<!--<b>Preface of the book:</b> <a href="./publications/roederer/prefacio.pdf">[Link]</a><br>
						<b>Presentation of the book at the National Physics Meeting 2016:</b> <a href="http://www.youtube.com/watch?v=6jDjraKQ8oY">[Youtube link]</a><br>
						<b>Media coverage:</b> <a href="http://nexciencia.exactas.uba.ar/el-autor-en-persona">[Link]</a><br>-->
					</div>
				</td>
			</tr>

		</table>

		<!-- ################################################################ -->
		<h2 id="patents">Patents</h2>
		<table class="publications">
			<tr>
				<td style="width:220px;">
					<!--<a href="">-->
						<img style="width:150px;" src="./publications/ihypertime2022/ihypertime_nf_1stpage.jpg">
					<!--</a>-->
				</td>
				<td>
					<b>Method and System for Generation of Interpretable Time Series with Implicit Neural Representations</b><br>
					Elizabeth Fons, Svitlana Vyetrenko, Yousef El-Laham, Alejandro Sztrajman, Alexandros Iosifidis<br>
					<span id="venue">US Patent App. 18/215, 499 (Pending, 2024)</span><br>
					<div id="links">
						<!--<a href="https://patents.justia.com/patent/20240104358">Page</a>-->
						<a href="https://www.patents-review.com/a/20240104358-method-system-generation-interpretable-time-series-implicit.html">Page</a>
					</div>
				</td>
			</tr>

			<tr>
				<td style="width:220px;">
					<a href="https://scholar.google.com/scholar?oi=bibs&cluster=5095571253552234732&btnI=1&hl=en">
						<img style="width:150px;" src="./publications/3dv2020/img/3dv-patent-cover.png">
					</a>
				</td>
				<td>
					<b>Estimating Illumination in an Environment Based on an Image of a Reference Object</b><br>
					Alexandros Neophytou, Eric Sommerlade, <b>Alejandro Sztrajman</b>, Sunando Sengupta<br>
					<span id="venue">US Patent 0116549 A1 (2022).</span><br>
					<div id="links">
						<!--<a href="https://scholar.google.com/scholar?oi=bibs&cluster=5095571253552234732&btnI=1&hl=en">Page</a>-->
						<a href="https://patents.google.com/patent/US11330196B2/en">Page</a>
						<a href="https://www.freepatentsonline.com/20220116549.pdf">PDF</a>
					</div>
				</td>
			</tr>
		</table>

		<!-- ################################################################ -->
		<!--<h2 id="articles">Short Articles</h2>-->
		<!--<table class="blog">
			<col width="60px">
			<col width="800px" align="left">

			<tr>
				<td><img src="./img/net.svg" width="90%"></td>
				<td>
					<a href="./blog/rnvp/rnvp.html">Generative Models &mdash; Real NVP Networks</a><br>
					<span>June 2021</span>
				</td>
			</tr>

			<tr>
				<td><img src="./img/stats_thumb.png" width="100%"></td>
				<td>
					<a href="./blog/stats/friedman.html">Statistical Analysis &mdash; Friedman Test</a><br>
					<span>July 2021</span>
				</td>
			</tr>
		</table>-->
		<!-- ################################################################ -->
		<h2 id="talks">Talks</h2>
		<table class="talks">
			<col width="60px">
			<col width="800px" align="left">

			<tr>
				<td id="logo"><img src="./img/cam2.png" width="90%"></td>
				<td>
					<b>Relightable 3D Gaussian Splatting</b><br>
					<span id="venue">University of Cambridge, 19 Dec 2023.</span><br>
					<div id="links">
						<a href="./talks/cambridge/Relightable_3DGS_slides.pdf">Slides</a>
					</div>
				</td>
			</tr>

			<tr>
				<td id="logo"><img src="./img/cam2.png" width="90%"></td>
				<td>
					<b>Neural Radiance Fields</b><br>
					<span id="venue">Homerton College, University of Cambridge, 14 Aug 2023 | Cambridge Summer Course.</span><br>
					<div id="links">
						<a href="./talks/cambridge/neural_radiance_fields.pdf">Slides</a>
					</div>
				</td>
			</tr>

			<tr>
				<td id="logo"><img src="./talks/brown/brown_logo..png" width="90%"></td>
				<td>
					<b>Neural Fields for Data Representation and Generation</b><br>
					<span id="venue">Brown University, 17 Oct 2022.</span><br>
					<div id="links">
						<a href="./talks/brown/neural_fields.pdf">Slides</a>
					</div>
				</td>
			</tr>

			<tr>
				<td id="logo"><img src="./publications/3dv2020/img/3dv-logo2.png" width="100%"></td>
				<td>
					<b>High-Dynamic-Range Lighting Estimation from Face Portraits</b><br>
					<span id="venue">Virtual, 27 Nov 2020 | International Conference on 3D Vision.</span><br>
					<div id="links">
						<a href="./publications/3dv2020/3dv-long+notes.pdf">Slides</a>
						<a href="./publications/3dv2020/3dv2020.html#short">Short Presentation</a>
						<a href="./publications/3dv2020/3dv2020.html#long">Long Presentation</a>
						<a href="./publications/3dv2020/3dv2020.html#poster">Poster</a>
					</div>
				</td>
			</tr>

			<tr>
				<td id="logo"><img src="./talks/microsoft/microsoft.png" width="100%"></td>
				<td>
					<b>CNN-based Face Relighting</b><br>
					<span id="venue">Microsoft, Seattle, USA (virtual), 12 Mar 2020.</span><br>
					<!--<div id="tags">
						<li><s>Slides</s></li>
					</div>-->
				</td>
			</tr>

			<tr>
				<td id="logo"><img src="./talks/eth/eth.png" width="100%"></td>
				<td>
					<b>Capture and Editing of Material Appearance</b><br>
					<span id="venue">ETH, Zurich, Switzerland. 5 Feb 2018.</span><br> <!-- DISTRO -->
					<div id="links">
						<a href="./talks/eth/presentation_ethz_2018.pdf">Slides</a>
					</div>
				</td>
			</tr>

			<tr>
				<td id="logo"><img src="./talks/ist/ist.svg" width="100%"></td>
				<td>
					<b>Introduction to Convolutional Neural Networks</b><br>
					<span id="venue">IST, Vienna, Austria. 14 Nov 2017.</span><br> <!--| As part of the Deep Learning Workshop organized by DISTRO-ITN-->
					<div id="links">
						<a href="./talks/ist/ist_presentation.pdf">Slides</a>
						<a href="https://github.com/asztr/WienTrainingWeek">Course Materials</a>
					</div>
				</td>
			</tr>

			<tr>
				<td id="logo"><img src="./publications/mam2017/eg-logo.png" width="100%"></td>
				<td>
					<b>Image-based Remapping of Material Appearance</b><br>
					<span id="venue">Helsinki, Finland, 18 Jun 2017 | Eurographics Workshop on Material Appearance Modelling.</span><br>
					<div id="links">
						<a href="./publications/mam2017/mam2017_presentation.pdf">Slides</a>
					</div>
				</td>
			</tr>

		</table>
		<!--  ################################################################ -->
		<!-- <h2 id="codes">Some Old Codes</h2>
		<div style="margin-left: 40px; white-space: nowrap; vertical-align:top;">
			<table class="projects">
				<tr>
					<td>
						<img id="nobox" src="./projects/hmm/hmm1.jpg">
					</td>
					<td>
						<b>Feature Saliency HMM</b><br>
						Implementation of the Feature Saliency HMM algorithm, for feature selection on Hidden Markov Models.
						<br>
						<a href="https://github.com/elifons/FeatureSaliencyHMM">[Code]</a>
						<div id="tags">
							<li>Python</li>
							<li>Hidden Markov Model</li>
						</div>
					</td>
				</tr>
				<tr>
					<td>
						<img src="./projects/shirley/shirley.jpg">
					</td>
					<td>
						<b>Path tracing</b><br>
						A path tracer with support for environment map illumination.
						<br>
						<a href="https://github.com/asztr/shirley-based-raytracer">[Code]</a>
						<div id="tags">
							<li>C++</li>
							<li>Global Illumination</li>
						</div>
					</td>
				</tr>
				<tr>
					<td>
						<a href="./projects/lbe2d/lbe2d-reel2.mp4">
							<video muted loop preload="auto" onmouseover="this.play()" onmouseout="this.pause()">
								<source src="./projects/lbe2d/lbe2d_thumbnail2.mp4#t=0.01" type="video/mp4;">
							</video>
						</a>
					</td>
					<td>
						<b>2D Lattice-Boltzmann Simulation</b><br>
						Interactive simulation of incompressible viscous fluid with Lattice-Boltzmann D2Q9.<br>
						<a href="https://github.com/asztr/lbe2d">[Code]</a>
						<a href="./projects/lbe2d/lbe2d-reel2.mp4">[Video]</a>
						<div id="tags">
							<li>C++</li>
							<li>Qt</li>
							<li>Physics-based Animation</li>
						</div>
					</td>
				</tr>
				<!- -<tr>
					<td>
						<a href="./projects/elastic-mesh/elastic-mesh-reel2.mp4">
							<video id="nobox" muted loop preload="auto" onmouseover="this.play()" onmouseout="this.pause()">
								<source src="./projects/elastic-mesh/mesh_thumbnail.mp4#t=0.01" type="video/mp4;">
								<img src="./projects/elastic-mesh/elastic-mesh.png">
							</video>
						</a>
					</td>
					<td>
						<b>2D Elastic mesh</b><br>
						Real-time simulation of a bi-dimensional elastic mesh.<br>
						<a href="./projects/elastic-mesh/elastic-mesh-reel2.mp4">[Video]</a>
						<div id="tags">
							<li>C++</li>
							<li>OpenGL</li>
							<li>Physics-based Animation</li>
						</div>
					</td>
				</tr>
				<tr>
					<td>
						<img src="./projects/aslam/aslam_thumbnail2.jpg">
					</td>
					<td>
						<b>High-order extrapolation</b><br>
						A differential equation approach to high-order extrapolation.
						<br>
						<a href="./projects/aslam/aslam.pdf">[Report]</a>
					</td>
				</tr>- ->
			</table>-->
			<!--<table class="projects">
				<tr>
					<td>
						<img id="nobox" src="./projects/utia-brdf/utia_spheres3.jpg">
					</td>
					<td>
						<b>UTIA BRDF Reader</b><br>
						Script to read measured BRDF data from the <a href="http://btf.utia.cas.cz/?brdf_dat_dwn">UTIA BRDF database</a>.
						<br>
						<a href="https://github.com/asztr/UTIA-brdf">[Code]</a>
						<div id="tags">
							<li>Python</li>
							<li>BRDF</li>
						</div>
					</td>
				</tr>
				<tr>
					<td>
						<a href="./projects/phong/phong_reel2.mp4">
							<video muted loop preload="auto" onmouseover="this.play()" onmouseout="this.pause()">
								<source src="./projects/phong/phong_thumbnail.mp4#t=1.1" type="video/mp4;">
							</video>
						</a>
					</td>
					<td>
						<b>WebGL 3D Engine</b><br>
						An interactive WebGL 3D engine with phong shading and support for Bezier surfaces.<br>
						<a href="./projects/phong/phong_reel2.mp4">[Video]</a>
						<a href="https://github.com/asztr/webgl-3Dengine">[Code]</a>
						<a href="./projects/phong/engine/index.html">[Try it!]</a>
						<div id="tags">
							<li>Javascript</li>
							<li>WebGL</li>
						</div>
					</td>
				</tr>
				<tr>
					<td>
						<a href="./projects/flip2d/flip2d_reel2.mp4">
							<video muted loop preload="auto" onmouseover="this.play()" onmouseout="this.pause()">
								<source src="./projects/flip2d/flip2d_thumbnail.mp4#t=0.01" type="video/mp4;">
							</video>
						</a>
					</td>
					<td>
						<b>2D FLIP Simulation</b><br>
						Fluid Implicit Particle (FLIP) simulation of a 2D incompressible inviscid fluid.
						<br>
						<a href="https://github.com/asztr/flip2d">[Code]</a>
						<a href="./projects/flip2d/flip2d.mp4">[Video]</a>
						<div id="tags">
							<li>C++</li>
							<li>Qt</li>
							<li>Physics-based Animation</li>
						</div>
					</td>
				</tr>
			</table>
		</div>-->
		<!--<td>
			<a href="./projects/moldyn/moldyn.mp4">
				<video muted loop preload="auto" onmouseover="this.play()" onmouseout="this.pause()">
					<source src="./projects/moldyn/moldyn_thumbnail.mp4#t=0.01" type="video/mp4;">
				</video>
			</a>
		</td>
		<td>
			<b>Molecular dynamics</b><br>
			Lagrangian simulation of a fluid at a molecular level. Integration is done with velocity-Verlet,
			Lennard-Jones interactions, and periodic boundary conditions (C++/VMD).
			<br>
			<a href="./projects/moldyn/moldyn-report.pdf">[Report (Spanish)]</a>
			<a href="./projects/moldyn/moldyn.mp4">[Video]</a>
		</td>-->
		<!-- ################################################################ -->
		<h2 id="teaching">Teaching</h2>
		<table class="teaching">
			<col width="4em">
			<col width="auto">
			<col width="140">
			<col align="right" width="auto">
			<tr>
				<td><b>2023</b></td>
				<td><a href="https://www.cl.cam.ac.uk/teaching/2324/AGIP/">Advanced Graphics and Image Processing</a></td>
				<td></td>
				<td>Cambridge</td>
			</tr>
			<tr>
				<td><b>2023</b></td>
				<td><a href="https://www.cl.cam.ac.uk/teaching/2324/Graphics/">Introduction to Graphics</a></td>
				<td></td>
				<td>Cambridge</td>
			</tr>

			<!--<tr>
				<td><b>2019</b></td>
				<td>Introduction to Virtual Reality (MOOC)</td>
				<td></td>
				<td>UCL/IDEALondon (<i>In development</i>)</td>
			</tr>-->
			<tr>
				<td><b>2019</b></td>
				<!--<td><a href="http://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs">Advanced Deep Learning and Reinforcement Learning</a></td>-->
				<td>
					<a href="https://www.ucl.ac.uk/module-catalogue/modules/reinforcement-learning/COMP0089">Advanced Deep Learning and Reinforcement Learning</a>
					<!--<a href="http://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs"> <img src="./img/youtube-logo.png" height="20px"/></a>-->
				</td>
				<!--<td><a href="http://www.cs.ucl.ac.uk/1819/A7P/T2/COMP0089_Advanced_Deep_Learning_and_Reinforcement_Learning/"></a></td>-->
				<td></td>
				<td>UCL/DeepMind</td>
			</tr>
			<tr>
				<td><b>2018</b></td>
				<td><a href="http://web4.cs.ucl.ac.uk/teaching/GV16/">Research Methods and Reading</a></td>
				<td></td>
				<td>UCL</td>
			</tr>
			<tr>
				<td><b>2017</b></td>
				<td><a href="http://ucl-cs-grad.github.io/scipython/">Scientific Programming in Python</a> <img src="./img/python-logo.png" height="16px"/></td>
				<td></td>
				<td>UCL</td>
			</tr>
			<tr>
				<td><b>2016</b></td>
				<td><a href="http://www.cs.ucl.ac.uk/current_students/syllabus/undergrad/105p_robotics_programming/">Robotics Programming</a></td>
				<td></td>
				<td>UCL</td>
			</tr>
			<tr>
				<td><b>2016</b></td>
				<td><a href="http://www.cs.ucl.ac.uk/students/syllabus/undergrad/101p_principles_of_programming/">Principles of Programming</a></td>
				<td></td>
				<td>UCL</td>
			</tr>
		</table>
		<!-- ################################################################ -->
		<!-- <h2 id="bground">Background</h2>
		<table class="bground">
			<col width="60px">
			<col width="800px">

			<tr>
				<td><img src="./img/logo-ucl3.png" width="100%"></td>
				<td>
					I did my PhD in Computer Science in the
					<a href="https://reality.cs.ucl.ac.uk/">Digital Reality Lab</a> at
					<a href="">University College London</a>, under the supervision of Profs.
					<a href="https://reality.cs.ucl.ac.uk/weyrich.html">Tim Weyrich</a> and
					<a href="http://www.homepages.ucl.ac.uk/~ucactri/">Tobias Ritschel</a>.
					The funding was provided by a
					<i>Marie Curie Fellowship</i> granted by the
					<i>European Commission</i> as part of the
					<a href="http://www.distro-itn.eu">DISTRO</a> Innovative Training Network.
				</td>
			</tr>

			<tr>
				<!- -<td><img src="./img/logo-microsoft.png" width="90%"></td>- ->
				<td><img src="./talks/microsoft/microsoft.png" width="90%"></td>
				<td>
					I did an 8-months research internship
					<!- -in the <a href="https://www.microsoft.com/applied-sciences">Applied Sciences Group</a>- ->
					at Microsoft UK, under the supervision of
					<a href="https://www.microsoft.com/applied-sciences/people/eric-sommerlade">Eric Sommerlade</a> and
					<a href="https://www.microsoft.com/applied-sciences/people/alexandros-neophytou">Alexandros Neophytou</a>.
					During this time I worked on HDR light estimation from images using CNNs and GANs.
					Part of this work was patented and published at the
					<a href="./publications/3dv2020/3dv2020.html">International Conference on 3D Vision 2020</a>.
				</td>
			</tr>

			<tr>
				<td><img src="./img/logo-adobe3.png" width="90%"></td>
				<td>
					I did a 4-months research internship at
					<a href="https://www.substance3d.com/">Adobe Substance 3D</a> in Clermont-Ferrand, France, under the supervision of
					<a href="https://fr.linkedin.com/in/cyrille-damez-53183a">Dr Cyrille Damez</a>.
					During this time I worked on the translation of material appearance between different renderers.
					<!- -The work was published at the 
					<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman2019image-based.html">Journal of Computer Graphics Techniques</a>.- ->
				</td>
			</tr>

			<tr>
				<td><img src="./img/logo-charles-university.png" width="90%"></td>
				<td>
					I spent 3 months as visiting student in the
					<a href="https://cgg.mff.cuni.cz/">Computer Graphics Group</a> at
					<a href="https://en.wikipedia.org/wiki/Charles_University">Charles University</a> in Prague.
					During this time I started working on material appearance remapping under the supervision of Profs.
					<a href="https://cgg.mff.cuni.cz/~jaroslav/">Jaroslav Křivánek</a> and
					<a href="https://cgg.mff.cuni.cz/members/wilkie/">Alexander Wilkie</a>.
					<!- -The work was published at the
					<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman17image-based.html">Eurographics Material Appearance Modeling Workshop</a> and later extended to cover spatially-varying materials and published at the
					<a href="http://reality.cs.ucl.ac.uk/projects/reflectance-remapping/sztrajman2019image-based.html">Journal of Computer Graphics Techniques</a>.- ->

				</td>
			</tr>

			<tr>
				<td><img src="./img/logo-columbia2.png" width="100%"></td>
				<td>
					<!- -During 2013- ->
					I spent 6 months as visiting student in the
					<a href="http://www.cs.columbia.edu/cg/">Columbia Computer Graphics Group</a> at
					<a href="https://www.columbia.edu/">Columbia University</a> in New York City.
					During this time I worked on physics-based animation of fluids under the supervision of Profs.
					<a href="https://cs.uwaterloo.ca/~c2batty/">Christopher Batty</a> and
					<a href="https://www.dgp.toronto.edu/~eitan/">Eitan Grinspun</a>.
				</td>
			</tr>

			<tr>
				<td><img src="./img/logofcen.png" width="100%"></td>
				<td>
					I hold a BSc degree in Physics from the
					<a href="https://en.wikipedia.org/wiki/University_of_Buenos_Aires">University of Buenos Aires</a>.
					<!- -There, I worked as research student on physics-based simulations at the
					Astrophysical Flows Group.- ->
				</td>
			</tr>
		</table>-->

		<!-- ################################################################ -->
	</div>

	<br><br><br><br>
	<div class="footer">
		<div class="footer-text">
			Alejandro Sztrajman<br>
			<a href="alejandro.sztrajman@cl.cam.ac.uk">alejandro.sztrajman@cl.cam.ac.uk</a>
		</div>
	</div>
</body>
</html>
